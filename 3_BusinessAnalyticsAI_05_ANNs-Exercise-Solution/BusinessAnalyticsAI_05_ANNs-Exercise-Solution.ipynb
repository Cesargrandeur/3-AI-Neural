{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics and Artificial Intelligence\n",
    "Summer semester 2024\n",
    "\n",
    "Prof. Dr. JÃ¼rgen Bock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises regarding foundations of artificial neural networks in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook offers exercises for the basics of artificial neural networks in *PyTorch*. The single tasks are described in Markdown cells. Enter your solution in the code cell following the task description, and add further code cells if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "* You are able to implement simple artificual neurons and to analyse the influence of the single components.\n",
    "* You are able to prepare structured data sets for their use in *PyTorch* and to define simple multi-layered neural networks.\n",
    "* You are able to embed your own neural networks in a generic learning algorithms and to train it with different data sets.\n",
    "* You are able to analyse and discuss the effect of different hyperparameters on the learning process and the quality of the learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the Boolean function *NAND*.\n",
    "\n",
    "The truth table for NAND is as follows:\n",
    "\n",
    "| NAND | 0 | 1 |\n",
    "|-----|---|---| \n",
    "| **0**   | 1 | 1 |\n",
    "| **1**   | 1 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this function computable with a single neuron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* It is linearly separable, i.e., the samples of the single classes are separable by a linear function (here: a strait line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would this single neuron need to be configured (inputs, weights)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* The two inputs will be weighted negatively, the bias positively. It is important that the effect of the bias makes the input sum greater 0 if and only if at most one of the two inputs is 1, i.e., if the input weight contributes to the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the computation in Python and test your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 1\n",
    "x2 = 1\n",
    "\n",
    "w03 = 1.5\n",
    "w13 = -1\n",
    "w23 = -1\n",
    "\n",
    "y = threshold(w03 + x1*w13 + x2*w23)\n",
    "print('{} NAND {} -> {}'.format(x1, x2, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layered neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following (synthecital) data set with two features and two classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.make_circles(\n",
    "    n_samples = 10000,\n",
    "    noise = 0.1,\n",
    "    factor = 0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make yourself familiar with this data set by creating a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = data\n",
    "plt.scatter(X[:,0], X[:,1], c=t, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a multi-layered neural network using *PyTorch* and implement a training routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(t))\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP( nn.Module ):\n",
    "    def __init__( self ):\n",
    "        super( MLP, self ).__init__()\n",
    "        self.fc1 = nn.Linear( 2, 10 )\n",
    "        self.fc3 = nn.Linear( 10, 1 )\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        x = torch.sigmoid( self.fc1( x ) )\n",
    "        x = torch.sigmoid( self.fc3( x ) )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from statistics import mean\n",
    "loss_history = []\n",
    "loss_ep = []\n",
    "plt.figure(figsize = (12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader :\n",
    "        optimizer.zero_grad()\n",
    "        input, target = batch\n",
    "        output = model(input.float())\n",
    "        loss = loss_fn(output, torch.unsqueeze(target.float(), 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep.append(loss.item())\n",
    "    \n",
    "    ## Zu Visualisierungszwecken:\n",
    "    loss_history.append(mean(loss_ep))\n",
    "    loss_ep = []\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(loss_history)\n",
    "    #dataview.plot_decision_boundary2d(model, X, t, showData=False)\n",
    "    display.display(plt.gcf())\n",
    "    display.display(print(\"Epoch {:2}, loss: {}\".format(epoch, loss_history[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the module ``dataview`` is in the current directory (or in ``sys.path``). Use the function ``dataview.plot_decision_boundary2d(model, X, y)`` in order to visualize the *decision boundary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataview.plot_decision_boundary2d(model, X, t, showData=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the so-called *hyperparameters*: Change the number of and width of the layers, change the number of epochs and the *batch size*. Have a look at the *PyTorch* API documentation and experiment with different activation functions and optimizers.\n",
    "\n",
    "**Note:** After changing the model, the object instance of the model must be re-initialized (e.g. ``model = Net()``). Also, the optimizer and other auxiliary variebles, e.g., a ``loss_history``, etc., must be re-initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which were your finding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "- A network with a single *hidden layer* is sufficient for solving this classification problem. 3 neurons in the *hidden layer* makes a are working solution. The more neurons there are in the *hidden layer* the more accurately the circle is approximated.\n",
    "- The *sigmoid* function works as an activation function.\n",
    "- Robustness and speed of convergence depend on the optimizer. *Adam* works significantly better than *SGD*.\n",
    "- The *learning rate* is differently effective for both optimization algorithms. This classification problem is relatively robust against larger learning rates. Obviously there are not bigger problems due to local minima in the weight space.\n",
    "- A small *batch size* (even of size 1) leads to a significant slow-down of the iterations over the epochs. However, even after one epoch, a reasonably accurate approximation is found. A large *batch size* leads to a fast iteration over the epochs, the convergence is slower. The model would be more robust against overfitting (\"Learning exactly the training data set\"). This effect cannot be observed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ``scikit-learn`` to obtain the *Breast Cancer Wisconsin* data set. See: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of features:', len(data.feature_names))\n",
    "print(data.feature_names)\n",
    "print('Number of classes:', len(data.target_names))\n",
    "print(data.target_names)\n",
    "print('Number of samples:', len(data.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make yourself familiar with the function ``train_test_split`` from the module ``sklearn.model_selection``. Use this function to split the data set into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a neural network and use the training data set to train it. Note the lengths of input and output vector when defining the network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(t_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset_train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__( self ):\n",
    "        super( MLP, self ).__init__()\n",
    "        self.fc1 = nn.Linear( 30, 50 )\n",
    "        self.fc2 = nn.Linear( 50, 20 )\n",
    "        self.fc3 = nn.Linear( 20, 5 )\n",
    "        self.fc4 = nn.Linear( 5, 1 )\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        x = F.relu( self.fc1( x ) )\n",
    "        x = F.relu( self.fc2( x ) )\n",
    "        x = F.relu( self.fc3( x ) )\n",
    "        x = torch.sigmoid( self.fc4( x ) )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "loss_history = []\n",
    "loss_ep = []\n",
    "plt.figure(figsize = (12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader :\n",
    "        optimizer.zero_grad()\n",
    "        input, target = batch\n",
    "        output = model(input.float())\n",
    "        loss = loss_fn(output, torch.unsqueeze(target.float(), 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep.append(loss.item())\n",
    "    \n",
    "    ## Zu Visualisierungszwecken:\n",
    "    loss_history.append(mean(loss_ep))\n",
    "    plt.plot(loss_history)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    display.display(print(\"Epoch {:2}, loss: {}\".format(epoch, loss_history[-1])))\n",
    "    loss_ep = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ``scikit-learn`` to create a *classification report*, based on which you can evaluate your model.\n",
    "\n",
    "To do this, first compute the ouput vector using your neural network for the input vectors of the test data set.\n",
    "\n",
    "**Note:** ``torch.from_numpy`` creates a tensor from a *NumPy* array, which is the data structure of the test data sets. Also, you need to convert the input vector into a ``FloatTensor``.\n",
    "\n",
    "For *classification report* you need to convert the floating point numbers from the output vector (resulting from the ``sigmoid`` activation function) to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model(torch.from_numpy(X_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(t_test, torch.round(y_test).int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(t_test, torch.round(y_test).int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
