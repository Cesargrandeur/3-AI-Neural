{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics and Artificial Intelligence\n",
    "Summer semester 2024\n",
    "\n",
    "Prof. Dr. JÃ¼rgen Bock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "* You are able to explain the difference between model parameters and hyperparameters and to name some hyperparameters.\n",
    "* You are able to formulate the main steps to prepare data sets and to apply several methods to get an overiew over a data set.\n",
    "* You can explain the approach for encoding the output of multi-class classifier networks, you can draft the principle of suitable activation functions, and you are able to interpret the output of such activation functions.\n",
    "* You are able to apply artificial neural networks for multi-class classification and to evaluate the trained models according to suitable metrics.\n",
    "* You are able to tell the main principle of convolutional neural networks for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish between two kinds of parameters:\n",
    "- model parameters\n",
    "- hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model parameters** are those parameters that represent tha actual (learned) model. In the case of neural networks these are the **weights**. If, for instance, the neural network was trained to recognize cats on images, the model parameters (weights) characterize the model of cat images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters** are those parameters, that characterize the structure of the model and of the training procedure. All configuration levers that can be changed during the training phase are hyperparameters. Among them are:\n",
    "- Structure of the neural network\n",
    "  - Number of layers\n",
    "  - Number of neurons per layer\n",
    "  - Kind of interconnection (fully connected, convolutional, etc.)\n",
    "- Number of training epochs\n",
    "- Batch size in batch training\n",
    "- Choice of the *loss function*\n",
    "- Choice of the optimizer\n",
    "- Learning rate\n",
    "- Encoding of the results in the ouput vector\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the hyperparameters is one of the most difficult tasks during the training of neural networks. Often the effects of certain hyperparameters cannot be determined systematically. Also there can be correlations betweek hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks for Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have a closer look at some hyperparameters when we look at a prominent application of neural networks: image recognition\n",
    "\n",
    "More precisely, this is the classification of the content of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data are more complex than the synthetic data that we used so far, or than the simple classification data sets, e.g. *iris*.\n",
    "\n",
    "In classical image recognition approaches, a certain set of image features is detected and extracted in a preprocessing step. (Edges, etc.)\n",
    "\n",
    "In neural networks, however, every pixel of the image is considered a feature. Hence, the input vector of the neural network can be quite large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, given an image of the size 32 x 32 pixel in 3 color channels, we need an input vector of the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possibility to process input vectors of this size was achieved via recent advances in the are of neural networks:\n",
    "- Availability of large data sets\n",
    "- Availability of high-performance computing power\n",
    "- Novel / improved algorithms\n",
    "\n",
    "These advances allow for the definition and training of large neural networks with many layers and a large number of neurons (and thus also large input vectors). Training and evaluation of models with such many-layered architectures in called *Deep Learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of Image Data with PyTorch / Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `torchvision` library contains several useful packages and modules for loading, organizing and manipulating image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package `datasets` in ``torchvision`` contains modules for loading freely available and frequently used image data sets (e.g. for benchmarking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package `transforms` contains classes for transformation of image data (e.g. converting to tensors, re-scaling, normalizing, cropping, ...). Transformations can on the one hand be used to convert images into a format that is useable by the neural network. On the other hand, they can be used to augment the training data, e.g., by using different image crops or rotations, mirrored or distorted images, using different saturation, contrast, brightness, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformations can be passed directly to the data set representation. They are applied by the data set object directly.\n",
    "\n",
    "Firstly, however, the transformation object must be configured and instantiated. The class `Compose` accepts a list of `transform` objects during instantiation, that will be applied sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchvision` can download known data sets directly and place in a provided directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_cifar100 = \"c:/data/cifar100/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data are already present at the provided location, the download is skipped.\n",
    "\n",
    "Depending on the data set different options are available, e.g., if the data set contains test and training data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cifar100_train = datasets.CIFAR100( \n",
    "    root=root_dir_cifar100,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cifar100_test = datasets.CIFAR100( \n",
    "    root=root_dir_cifar100,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of readability, we use shorter variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataset_cifar100_train\n",
    "data_test = dataset_cifar100_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspection of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always useful to manually inspect the data first. Doing so we can test if the data is available in the right format, if they can be read and further processed, and, ideally, how certain hyperparameters must be set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it a training or test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data_train is a training data set:', data_train.train)\n",
    "print('data_test is a training data set:', data_test.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In which shape is the data available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape: ', data_train.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means: 50000 data samples of size 32 x 32 x 3 (i.e. 32 x 32 pixel in 3 color channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many and which classes are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of classes: \", len(data_train.classes))\n",
    "\n",
    "for i in range(0, len(data_train.classes)):\n",
    "    print(\"{:2d}  {}\".format(i, data_train.classes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many data samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples in training set:\", len(data_train.data))\n",
    "print(\"Number of samples in test set: \", len(data_test.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering and Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to the data is done, as we know already, via the `DataLoader` that in provided in the *PyTorch* package `torch.utils.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, we do not want to consider the complete data set, but only a fraction that contains certain target classes. To this end, we can configure a so-called `Sampler`, that extraxcts only a certain subset of the data sets. The sampler must be told the indices of the data samples to be considered. Hence, we have to identify the indices of these data samples for the required target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the selected classes based on their names and determine the class indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_selection = ['apple', 'pear', 'orange', 'mushroom', 'sweet_pepper']\n",
    "class_selection_idx = [i for i in range(len(data_train.classes)) if data_train.classes[i] in class_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indices of the classes\", class_selection, \":\", class_selection_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need only the indices of the data samples that are labeled with selected classes (for which the target is one of the identified class indices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the whole target vector first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the indices of the target vector at which is represents one of the selected classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = [i for (i,t) in enumerate(data_train.targets) if t in class_selection_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a verification, here is the target vector itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([data_train.targets[i] for i in target_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the `Sampler` using the index list. The sampler classes can be found in the package `torch.utils.data.sampler`. We use the `SubsetRandomSampler` based on the indices that characterize the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampler = SubsetRandomSampler(target_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual `DataLoader` can now be created for the `dataset` providing the `batch_size` and the `sampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=data_train, batch_size=50, sampler=data_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ``DataLoader`` we can now for the first time iterate over the images and have a look at them. Since we are using our configured ``SubsetRandomSampler`` we see only images of the selected classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the provided ``dataview`` module (that should be placed in the same directory as this notebook) there is an auxiliary function to print images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the images batch-wise, as they are served by the ``DataLoader``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (input, _) in data_loader:\n",
    "    dataview.view_images(input, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and Output Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we define the length of the input vector: (32x32 pixel in 3 color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 32 * 32 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we used neural networks for binary classification only. There, the output layer consists of exactly one neuron, which (based on the *sigmoid* or *threshold* activation function) could produce output values (close to) 0 or (close to) 1, which corresponds to the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we address the problem of multi-class classification, i.e., there are more than 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a method to represent the different classes by the output of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two typical appraoches to encode classes:\n",
    "- Label Encoding\n",
    "- One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the **label encoding** every class is represented by a unique class index. In our case this would be, e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Klasse       | Label |\n",
    "|--------------|-------|\n",
    "| Apple        | 0     |\n",
    "| Pear         | 1     |\n",
    "| Orange       | 2     |\n",
    "| Mushroom     | 3     |\n",
    "| Sweet_Pepper | 4     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advantage is the compact representation of the class. A disadvantage is that the incremental numbering suggests a sequence that is not present. Especially, if the class label is used as a numerical input later, the number value can be misinterpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the **one-hot encoding**, a vector of length $n$ is used to represent $n$ classes. In this vector the index is representing the corresponding class. In an ideal classification result, all vector elements would be 0 apart from the one whose index represents the detected class, which would be 1. In our example this would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class        | Apple | Pear | Orange | Mushroom | Sweet_Pepper |\n",
    "|--------------|-------|------|--------|----------|--------------|\n",
    "| Apple        | 1     | 0    | 0      | 0        | 0            |\n",
    "| Pear         | 0     | 1    | 0      | 0        | 0            |\n",
    "| Orange       | 0     | 0    | 1      | 0        | 0            |\n",
    "| Mushroom     | 0     | 0    | 0      | 1        | 0            |\n",
    "| Sweet_Pepper | 0     | 0    | 0      | 0        | 1            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the one-hot encoding for representing the result vector in multi-class classification tasks with neural networks has a major advantage compared to the label encoding: The neural network does not compute unique class assertions with one vector element being 1 and all others being equal to 0. Instead, the ouput neurons are activated to a different extent. The more a neuron is activated the higher the probability of the resprective class. (This is a result presentation that cannot be realised using label encoding.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-class classification it is required to design a neural network such that its *output layer* has as many neurons as there are target classes. In order to convert the activations into a probability distribution the *Softmax* activation function can be used. It converts a vector $\\vec{a}$ of activations into an equaliy sized vector of probabilities $\\vec{y}$, such that for each vector element $y_i$ there is $y_i \\in [0, 1]$ and $\\sum_i y_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"softmax.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 5)\n",
    "print('Activations a:                  ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "print('Probabilities after softmax(a): ', softmax(a))\n",
    "print('Sum of the probabilities:       ', torch.sum(softmax(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also a frequently used activation function is *LogSoftmax*. This computes the logarithm of the results of the *Softmax* function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *LogSoftmax* function delivers values in the range $(-\\infty, 0]$. This can be explained by the logarithm function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "xdata = torch.linspace(0, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xdata, torch.log(xdata))\n",
    "plt.grid(True)\n",
    "plt.axvline(1, color=\"red\", linestyle=\"--\")\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This emphasizes higher probabilities (close to 1, close to 0 after the logarithm) and lower proabilities (close to 0) are further diminished (close to  $-\\infty$ after the logarithm). Besides this, the *LogSoftmax* function has several numerical and computational advantages over *Softmax*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsoftmax = nn.LogSoftmax(dim=1)\n",
    "print('Activations a:                           ', a)\n",
    "print('Probabilities according to softmax(a):   ', softmax(a))\n",
    "print('Activations according to  logsoftmax(a): ', logsoftmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(torch.arange(len(a.flatten())) -0.3, a.flatten(), 0.2, label=\"Activation\")\n",
    "plt.bar(torch.arange(len(a.flatten())) -0.1, softmax(a).flatten(), 0.2, label=\"Softmax\")\n",
    "plt.bar(torch.arange(len(a.flatten())) +0.1, logsoftmax(a).flatten(), 0.2, label=\"LogSoftmax\")\n",
    "plt.title(\"Comparision of activation functions.\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both *Softmax* and *LogSoftmax* activation - the length of the ouput vector corresponds to the number of target classes. In our example this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output = len(class_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_input)\n",
    "print(n_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a classical *multi-layer perceptron* as we know it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input, 200)\n",
    "        self.fc2 = nn.Linear(200, 50)\n",
    "        self.fc3 = nn.Linear(50, n_output)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, n_input)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer and  *loss function*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the performant optimization algorithm *Adam* for adjusting the weights (model parameters) with an appropriate *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a *loss function* for multi-class classification the *CrossEntropyLoss* is suitable according to the *BinaryCrossEntropy* for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``nn.CrossEntropyLoss`` function has an important property:\n",
    "\n",
    "It expects the prediction of the neural network and the target class as arguments in order to compute the loss.\n",
    "\n",
    "To this end, the result of the neural network has to be passed in as unnormalized vector that consists of the evaluations for the single classes. The normalization according to the *LogSoftMax* activation function is part of the *CrossEntrolyLoss* function and can be left out in the *forward pass* (in the training phase).\n",
    "\n",
    "The expected target class is provided as a scalar value that corresponds to the class index. The class index is a value in the range $[0, ..., numberClasses - 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our special case we have to convert the class indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_selection_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(range(len(class_selection_idx))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let the output vector of a neural network be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensor([[3.254, 0.252, 0.542, 6.233, 1.042]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target class index is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *CrossEntropyLoss* can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_fn(out, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop this has to be done batch-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensor([[3.253, 6.124, 0.346, 0.446, 1.153],\n",
    "                    [0.421, 5.255, 1.155, 0.421, 9.532],\n",
    "                    [0.221, 0.564, 1.435, 2.351, 0.532]])\n",
    "t = torch.tensor([1, 4, 3])\n",
    "print(loss_fn(out, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize training state during the iteration over the training loop, we need some auxiliary objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from statistics import mean\n",
    "loss_history = []\n",
    "loss_ep = []\n",
    "plt.figure(figsize = (12,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop iterated over the different epochs and within each epoch over the batches provided by the ``DataLoader``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above mentioned specialty of the *CrossEntropyLoss* function, the target argument has to be prepared in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs) :\n",
    "    for b, batch in enumerate(data_loader) :\n",
    "        optimizer.zero_grad()\n",
    "        input, target = batch\n",
    "        output = model(input)\n",
    "        # The target returned by the DataLoader is a tensor with the original class labels\n",
    "        # For the CrossEntropyLoss function we need to map this to a 1D tensor with each element \n",
    "        # a class index in [0, ..., number_of_classes-1]\n",
    "        t = torch.LongTensor(len(target))   # len(target) corresponds to the batch size\n",
    "        for i, e in enumerate(target):\n",
    "            t[i] = torch.tensor(class_selection_idx.index(e.item()))\n",
    "        loss = loss_fn(output, t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep.append(loss.item())   \n",
    "        \n",
    "    ## For visualization purposes:\n",
    "    loss_history.append(mean(loss_ep))\n",
    "    loss_ep = []\n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(loss_history)\n",
    "    display.display(plt.gcf())\n",
    "    display.display(print(\"Epoch {:2}, loss: {}\".format(epoch, loss_history[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the model, we use the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is prepared the same way as the training data set.\n",
    "\n",
    "Extraction of the data samples with selected classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_idx = [i for (i,t) in enumerate(data_test.targets) if t in class_selection_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an according ``SubsetRandomSampler`` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampler_test = SubsetRandomSampler(test_target_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and a ``DataLoader``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = DataLoader(dataset=data_test, batch_size=10, sampler=data_sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation functionality we use the classical metrics from ``scikit-learn``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two lists:\n",
    "\n",
    "- ``y_test`` to list the target classes from the test data set (expected classification)\n",
    "- ``y_pred`` to list the prediction by the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training we omitted the *LogSoftmax* activation because of the *CrossEntropyLoss* function. If we want to know the probabilities of the calculated class memberships we have to apply the *Softmax* function to the ouput of the model.\n",
    "\n",
    "Since the order (i.e. the ranking) of the class membership propabilities does not change, we can also determine class with the highest evaluation. This is done using the ``argmax`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.randn(1,5)\n",
    "print(l)\n",
    "print(l.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the winner classes of the model and the target classes in the ``y_pred`` and ``y_test`` classes that we initialized before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_test in data_loader_test:\n",
    "    input, target = batch_test\n",
    "\n",
    "    for t in target:\n",
    "        y_test.append(class_selection_idx.index(t.item()))\n",
    "\n",
    "    prediction = model(input)\n",
    "    \n",
    "    for y in prediction:\n",
    "        y_pred.append(y.argmax().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two lists can now be used to compute the *Confusion Matrix* and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', confusion)\n",
    "print('\\n\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=class_selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the neural networks considered so far, the image has to be converted into a long one-dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, features in an image can be found in an area of neighboring pixels. (In two dimensions.) This fact is used by *Convoluational Neural Networks* (CNNs). They take the image in its original dimensionality as an input. In a series of *feature detecting layers* neighboring pixel groups are convoluted and compressed (*pooling*). After that, several *fully connected* layers are typically used. These compute the classification based on the features detected before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how a Convolutional Neural Network can be defined in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=6, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(12, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((6, 6))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64*6*6, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, n_output)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the model, the optimizer must be reinitialized in order to make the new model parameters known to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an in-depth explanation of this principle, please use the literature and the PyTorch documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
